{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 페이스북 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프록시 서버 접속이 막혀서 동작 확인 미완료 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 11:28:22,419 http_request_randomizer.requests.useragent.userAgent INFO     Using local file for user agents: C:\\Users\\beaus\\Anaconda3\\lib\\site-packages\\http_request_randomizer\\requests\\proxy\\../data/user_agents.txt\n",
      "2021-07-13 11:28:22,424 root   DEBUG    === Initialized Proxy Parsers ===\n",
      "2021-07-13 11:28:22,425 root   DEBUG    \t FreeProxy parser of 'http://free-proxy-list.net' with required bandwidth: '150' KBs\n",
      "2021-07-13 11:28:22,426 root   DEBUG    \t PremProxy parser of 'https://premproxy.com/list/' with required bandwidth: '150' KBs\n",
      "2021-07-13 11:28:22,427 root   DEBUG    \t SslProxy parser of 'https://www.sslproxies.org' with required bandwidth: '150' KBs\n",
      "2021-07-13 11:28:22,428 root   DEBUG    =================================\n",
      "2021-07-13 11:28:23,830 root   DEBUG    Added 300 proxies from FreeProxy\n",
      "2021-07-13 11:28:25,049 http_request_randomizer.requests.parsers.PremProxyParser WARNING  Proxy Provider url failed: https://premproxy.com/list/\n",
      "2021-07-13 11:28:25,050 http_request_randomizer.requests.parsers.PremProxyParser DEBUG    Pages: set()\n",
      "2021-07-13 11:28:26,340 http_request_randomizer.requests.parsers.PremProxyParser WARNING  Proxy Provider url failed: https://premproxy.com/list/\n",
      "2021-07-13 11:28:26,341 root   DEBUG    Added 0 proxies from PremProxy\n",
      "2021-07-13 11:28:27,309 root   DEBUG    Added 100 proxies from SslProxy\n",
      "2021-07-13 11:28:27,310 root   DEBUG    Total proxies = 400\n",
      "2021-07-13 11:28:27,312 root   DEBUG    Filtered proxies = 400\n"
     ]
    }
   ],
   "source": [
    "import browser\n",
    "import page\n",
    "import re\n",
    "import json\n",
    "\n",
    "PAGE_URL = 'https://www.facebook.com/katckr/'\n",
    "TOR_PATH = browser.TOR_PATH.WINDOWS\n",
    "BROWSER_OPTIONS = browser.BROWSER_OPTIONS.CHROME\n",
    "\n",
    "USE_PROXY = True\n",
    "PRIVATE = True\n",
    "SPEED_UP = True\n",
    "HEADLESS = False\n",
    "\n",
    "SCROLL_DOWN = 10\n",
    "FILTER_CMTS_BY = page.FILTER_CMTS.MOST_RELEVANT\n",
    "VIEW_MORE_CMTS = 5\n",
    "VIEW_MORE_REPLIES = 2\n",
    "\n",
    "\n",
    "def get_child_attribute(element, selector, attr):\n",
    "    try:\n",
    "        element = element.find_element_by_css_selector(selector)\n",
    "        return str(element.get_attribute(attr))\n",
    "    except: return ''\n",
    "\n",
    "\n",
    "def get_comment_info(comment):\n",
    "    cmt_url = get_child_attribute(comment, '._3mf5', 'href')\n",
    "    utime = get_child_attribute(comment, 'abbr', 'data-utime')\n",
    "    text = get_child_attribute(comment, '._3l3x ', 'textContent')\n",
    "    cmt_id = cmt_url.split('=')[-1]\n",
    "\n",
    "    if cmt_id == None:\n",
    "        cmt_id = comment.get_attribute('data-ft').split(':\"')[-1][:-2]\n",
    "        user_url = user_id = user_name = 'Acc clone'\n",
    "    else:\n",
    "        user_url = cmt_url.split('?')[0]\n",
    "        user_id = user_url.split('https://www.facebook.com/')[-1].replace('/', '')\n",
    "        user_name = get_child_attribute(comment, '._6qw4', 'innerText')\n",
    "    return {\n",
    "        'id': cmt_id,\n",
    "        'utime': utime,\n",
    "        'user_url': user_url,\n",
    "        'user_id': user_id,\n",
    "        'user_name': user_name,\n",
    "        'text': text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Tor's SOCKS proxy server\n",
      "Go to page https://www.facebook.com/katckr/\n",
      "Redirect detected => Rerun\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    driver = browser.setup_driver(PAGE_URL, TOR_PATH, BROWSER_OPTIONS, USE_PROXY, PRIVATE, SPEED_UP, HEADLESS)\n",
    "    if driver.current_url in PAGE_URL:\n",
    "        if page.load(driver, PAGE_URL, SCROLL_DOWN, FILTER_CMTS_BY, VIEW_MORE_CMTS, VIEW_MORE_REPLIES): break\n",
    "    else: print(f\"Redirect detected => {'Rerun' if USE_PROXY else 'Please use proxy'}\\n\")\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "html_posts = driver.find_elements_by_css_selector(page.POSTS_SELECTOR)\n",
    "file_name = re.findall('\\.com/(.*)', PAGE_URL)[0].split('/')[0]\n",
    "total = 0\n",
    "\n",
    "print('Start crawling', len(html_posts), 'posts...')\n",
    "with open(f'data/{file_name}.json', 'w', encoding='utf-8') as f:\n",
    "    for post in html_posts:\n",
    "        post_url = get_child_attribute(post, '._5pcq', 'href').split('?')[0]\n",
    "        post_id = re.findall('\\d+', post_url)[-1]\n",
    "        utime = get_child_attribute(post, 'abbr', 'data-utime')\n",
    "        post_text = get_child_attribute(post, '.userContent', 'textContent')\n",
    "        total_shares = get_child_attribute(post, '[data-testid=\"UFI2SharesCount/root\"]', 'innerText')\n",
    "        total_cmts = get_child_attribute(post, '._3hg-', 'innerText')\n",
    "\n",
    "        json_cmts = []\n",
    "        html_cmts = post.find_elements_by_css_selector('._7a9a>li')\n",
    "\n",
    "        num_of_cmts = len(html_cmts)\n",
    "        total += num_of_cmts\n",
    "\n",
    "        if num_of_cmts > 0:\n",
    "            print(f'Crawling {num_of_cmts} comments of post {post_id}')\n",
    "            for comment in html_cmts:\n",
    "                comment_owner = comment.find_elements_by_css_selector('._7a9b')\n",
    "                comment_info = get_comment_info(comment_owner[0])\n",
    "\n",
    "                json_replies = []\n",
    "                html_replies = comment.find_elements_by_css_selector('._7a9g')\n",
    "\n",
    "                num_of_replies = len(html_replies)\n",
    "                total += num_of_replies\n",
    "\n",
    "                if num_of_replies > 0:\n",
    "                    print(f\"Crawling {num_of_replies} replies of {comment_info['user_name']}'s comment\")\n",
    "                    for reply in html_replies:\n",
    "                        reply_info = get_comment_info(reply)\n",
    "                        json_replies.append(reply_info)\n",
    "\n",
    "                comment_info.update({'replies': json_replies})\n",
    "                json_cmts.append(comment_info)\n",
    "\n",
    "        json_reacts = []\n",
    "        html_reacts = post.find_elements_by_css_selector('._1n9l')\n",
    "\n",
    "        for react in html_reacts:\n",
    "            react_text = react.get_attribute('aria-label')\n",
    "            json_reacts.append(react_text)\n",
    "\n",
    "        json.dump({\n",
    "            'url': post_url,\n",
    "            'id': post_id,\n",
    "            'utime': utime,\n",
    "            'text': post_text,\n",
    "            'reactions': json_reacts,\n",
    "            'total_shares': total_shares,\n",
    "            'total_cmts': total_cmts,\n",
    "            'crawled_cmts': json_cmts,\n",
    "        }, f, ensure_ascii=False)\n",
    "\n",
    "        del json_cmts\n",
    "        f.write('\\n')\n",
    "\n",
    "del html_posts\n",
    "print('Total comments and replies crawled:', total)\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
