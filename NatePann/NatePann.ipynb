{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이트판 톡커들의 선택(일간) 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '20210710' # 시작 날짜 입력\n",
    "end_date = '20210712'   # 종료 날짜 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글 링크 모으기 (하루 당 100개의 글 존재)\n",
    "def Get_url():\n",
    "    url_list = []\n",
    "    for date in range(int(start_date), int(end_date)+1):\n",
    "        for page in [1, 2]:\n",
    "            url = f'https://pann.nate.com/talk/ranking/d?stdt={date}&page={page}'\n",
    "            response = requests.get(url)\n",
    "            time.sleep(0.3)\n",
    "            if response.status_code != requests.codes.ok: # 접속 실패\n",
    "                print(\"접속 실패\")\n",
    "                continue\n",
    "\n",
    "            html = BeautifulSoup(response.text, 'html.parser')\n",
    "            tags = html.select('div.cntList dt a')\n",
    "\n",
    "            for tag in tags:\n",
    "                url_list.append('https://pann.nate.com'+tag.attrs['href'])\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본문 및 댓글 크롤링\n",
    "def Crawling(url_list):\n",
    "    content_list = [] # 본문 리스트\n",
    "    comment_list = [] # 댓글 리스트\n",
    "\n",
    "    for url in url_list:\n",
    "        # 페이지 접속\n",
    "        page_id = url[-9:]\n",
    "        response = requests.get(url)\n",
    "        time.sleep(1)\n",
    "        if response.status_code != requests.codes.ok: # 접속 실패\n",
    "            print(f\"{url} 접속 실패\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # 본문 가져오기\n",
    "        html = BeautifulSoup(response.text, 'html.parser')\n",
    "        tags = html.select('div#contentArea')\n",
    "        for tag in tags:\n",
    "            content = tag.text\n",
    "            content = content.replace('\\n', ' ')\n",
    "            content = content.replace('\\t', '')\n",
    "            content = content.replace('\\xa0', '')\n",
    "            if '이미지확대보기' in content: # 이미지 첨부된 경우\n",
    "                content = content.replace('이미지확대보기', '')\n",
    "            content_list.append(content)\n",
    "\n",
    "\n",
    "    #     # 베스트 댓글 (일반 댓글과 중복됨)\n",
    "    #     tags = html.select('div.cmt_best dd.usertxt span')\n",
    "    #     for tag in tags:\n",
    "    #         best_comment = tag.text\n",
    "    #         best_comment = best_comment.replace('\\n', ' ')\n",
    "    #         best_comment = best_comment.replace('\\t', '')\n",
    "    #         if '이미지확대보기' in best_comment: # 이미지 첨부된 경우\n",
    "    #             best_comment = best_comment.replace('이미지확대보기', '')\n",
    "    #         comment_list.append(best_comment)\n",
    "\n",
    "\n",
    "        # 일반 댓글\n",
    "        reply_page = 1\n",
    "        bef_tags = None\n",
    "        while True:\n",
    "            # 웹 버전에서는 댓글 페이지가 동적이어서 모바일 버전으로 가져옴\n",
    "            # 그럼 아예 모바일 버전으로 하면 되지 않나요? -> 모바일 버전에서는 댓글을 보려면 댓글 버튼을 눌러야해서 selenium 필요 ^^;\n",
    "            reply_url = f'https://m.pann.nate.com/talk/reply/view?pann_id={page_id}&page={reply_page}'\n",
    "            response = requests.get(reply_url)\n",
    "            time.sleep(0.5)\n",
    "            if response.status_code != requests.codes.ok: # 접속 실패\n",
    "                print(f\"{reply_url} 접속 실패\")\n",
    "                continue\n",
    "\n",
    "            html = BeautifulSoup(response.text, 'html.parser')\n",
    "            cur_tags = html.select('div#listDiv dd.userText')\n",
    "            if bef_tags == cur_tags:  # 댓글 마지막 페이지\n",
    "                break\n",
    "            bef_tags = cur_tags\n",
    "\n",
    "            for tag in cur_tags:\n",
    "                comment = tag.text\n",
    "                comment = comment.replace('\\n', ' ')\n",
    "                comment = comment.replace('\\t', '')\n",
    "                if '이미지확대보기' in comment: # 이미지 첨부된 경우\n",
    "                    comment = comment.replace('이미지확대보기', '')\n",
    "                comment_list.append(comment)\n",
    "\n",
    "            reply_page += 1\n",
    "    \n",
    "    return content_list, comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일로 저장\n",
    "def Save_csv(content_list, comment_list):\n",
    "    df = pd.DataFrame(content_list+comment_list, columns=[\"text\"])\n",
    "\n",
    "    # UnicodeEncodeError 에러 발생 시 해당 문자열을 제거해줌\n",
    "    # df = df.applymap(lambda x: x.replace('오류난 문자열',''))  \n",
    "\n",
    "    df.to_csv('./natepann.csv', mode = 'w', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    url_list = Get_url()\n",
    "    content_list, comment_list = Crawling(url_list)\n",
    "    Save_csv(content_list, comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
